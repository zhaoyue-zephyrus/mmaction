model = dict(
    type='TSN3D',
    backbone=dict(
        type='ResNet_X3D',
        pretrained=None,
        width_factor=2,
        depth_factor=2.2,
        bottleneck_factor=2.25,
        base_dim_conv1=12,
        dim_out=2048,
        num_stages=4,
        out_indices=[], # conv5 by default
        frozen_stages=-1,
        inflate_freq=(1, 1, 1, 1),
        conv1_kernel_t=5,
        bn_eval=False,
        partial_bn=False),
    spatial_temporal_module=dict(
        type='SimpleSpatialTemporalModule',
        spatial_type='identity',
        temporal_size=1,
        spatial_size=1),
    segmental_consensus=dict(
        type='SimpleConsensus',
        consensus_type='avg'),
    cls_head=dict(
        type='X3DHead',
        with_avg_pool=True,
        temporal_feature_size=4,
        spatial_feature_size=5,
        in_channels=432,
        fc_channels=2048,
        fc1_use_bn=False,
        dropout_ratio=0.5,
        num_classes=400))
train_cfg = None
test_cfg = None
# dataset settings
dataset_type = 'VideoDataset'
data_root = 'data/kinetics400/videos_train/'
data_root_val = 'data/kinetics400/videos_val/'
decoder='decord'
video_ext='mp4'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=False)
data = dict(
    videos_per_gpu=8,
    workers_per_gpu=2,
    train=dict(
        type=dataset_type,
        ann_file='data/kinetics400/kinetics400_train_list_videos.txt',
        img_prefix=data_root,
        img_norm_cfg=img_norm_cfg,
        input_format="NCTHW",
        num_segments=1,
        new_length=4,
        new_step=12,
        random_shift=True,
        modality='RGB',
        image_tmpl='img_{:05d}.jpg',
        img_scale=182,
        input_size=160,
        div_255=False,
        flip_ratio=0.5,
        resize_crop=True,
        resize_keep_ratio=True,
        oversample=None,
        random_crop=False,
        more_fix_crop=False,
        multiscale_crop=True,
        test_mode=False,
        decoder=decoder,
        video_ext=video_ext),
    val=dict(
        type=dataset_type,
        ann_file='data/kinetics400/kinetics400_val_list_videos.txt',
        img_prefix=data_root_val,
        img_norm_cfg=img_norm_cfg,
        input_format="NCTHW",
        num_segments=1,
        new_length=4,
        new_step=12,
        random_shift=False,
        modality='RGB',
        image_tmpl='img_{:05d}.jpg',
        img_scale=182,
        input_size=160,
        div_255=False,
        flip_ratio=0,
        resize_keep_ratio=True,
        oversample=None,
        random_crop=False,
        more_fix_crop=False,
        multiscale_crop=False,
        test_mode=True,
        decoder=decoder,
        video_ext=video_ext),
   test=dict(
        type=dataset_type,
        ann_file='data/kinetics400/kinetics400_val_list_videos.txt',
        img_prefix=data_root_val,
        img_norm_cfg=img_norm_cfg,
        input_format="NCTHW",
        num_segments=10,
        new_length=4,
        new_step=12,
        random_shift=True,
        modality='RGB',
        image_tmpl='img_{:05d}.jpg',
        img_scale=182,
        input_size=182,
        div_255=False,
        flip_ratio=0,
        resize_keep_ratio=True,
        oversample='three_crop',
        random_crop=False,
        more_fix_crop=False,
        multiscale_crop=False,
        test_mode=True,
        decoder=decoder,
        video_ext=video_ext))

optimizer = dict(type='SGD', lr=0.1, momentum=0.9, weight_decay=5e-5)
optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))
# learning policy
lr_config = dict(
    policy='cosine',
    warmup_ratio=0.01,
    warmup='linear',
    warmup_by_epoch=True,
    warmup_iters=35)

checkpoint_config = dict(interval=1)
workflow = [('train', 1)]
# yapf:disable
log_config = dict(
    interval=20,
    hooks=[
        dict(type='TextLoggerHook'),
        dict(type='TensorboardLoggerHook')
    ])
# yapf:enable
# runtime settings
total_epochs = 300
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './work_dirs/x3d_xs_kinetics400_se_rgb'
load_from = None
resume_from = None
